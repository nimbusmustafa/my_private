{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('/home/mustafa/ML_task/regression/winequality-red.csv')\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values[:, 0:len(df.columns)-1]\n",
    "y = df.values[:, len(df.columns)-1]\n",
    "def feature_normalize(x):\n",
    " mu = np.mean(x,axis=0)\n",
    " sigma = np.std(x,axis = 0, ddof=0, dtype=np.float64)\n",
    " x_norm = (x - mu)/sigma\n",
    " #y_norm =(y-(np.mean(y,axis=0)))/(np.std(y,ddof=0,dtype=np.float64))\n",
    " return x_norm, mu, sigma \n",
    "x_norm, mu, sigma = feature_normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.hstack((np.ones((len(df),1)), x_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    y_one_hot = np.zeros((len(y), 6))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        for k in range (3,9):\n",
    "            if(y[i]==k):\n",
    "                y_one_hot[i][k-3]=1\n",
    "            \n",
    "                     \n",
    "    return y_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot=one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x1, y_one_hot, test_size = 0.25, random_state = 605)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(x_train.shape[1])\n",
    "w = np.zeros((6,12))\n",
    "a=np.zeros((len(x_train),6))\n",
    "q=np.zeros((len(x_train),6))\n",
    "\n",
    "\n",
    "#z=np.dot(x_train,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w,x,a):\n",
    "    z=np.dot(x,w.T)\n",
    "    for i in range(len(x)):\n",
    "        for j in range(6):\n",
    "            a[i][j]= np.exp(z[i][j]) / (np.exp(z[i][0]) +np.exp(z[i][1]) +np.exp(z[i][2]) +np.exp(z[i][3]) +np.exp(z[i][4]) +np.exp(z[i][5]) )\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z= np.dot(x_train,w.T)\n",
    "a_final=softmax(w,x_train,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y,a):\n",
    "    loss=0\n",
    "    for i in range(len (y)):\n",
    "        for k in range (len (a[i])):\n",
    "            loss += y[i][k]*np.log(a[i][k])\n",
    "            j=-(1)*loss/len(a)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.791759469228055"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function(y_train,a_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def gradient_descent (x,a,y,w,q,alpha,epoch):\n",
    "    cost_history = np.zeros(epoch)\n",
    "\n",
    "    for i in range (epoch):\n",
    "        cost=0\n",
    "        q=y-a\n",
    "        cost= (alpha / len(x))*np.dot(x.T,q)\n",
    "        w=w+cost.T\n",
    "        a=softmax(w,x_train,a)\n",
    "\n",
    "        #print(a_final)\n",
    "        cost_history[i] = cost_function( y_train, a_final)  \n",
    "\n",
    "    return w, cost_history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_final,cost_list=gradient_descent(x_train,a_final,y_train,w,q,0.1,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.0 %\n"
     ]
    }
   ],
   "source": [
    "a_test=np.zeros((len(x_test),6))\n",
    "y_pred_prob = softmax(w_final,x_test,a_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "accuracy = np.mean(y_pred == np.argmax(y_test,axis=1))*100\n",
    "print(\"Accuracy:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
